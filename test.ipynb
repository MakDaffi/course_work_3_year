{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : NVIDIA GeForce RTX 2070 SUPER\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "############################### Import libraries ###############################\n",
    "\n",
    "\n",
    "import os\n",
    "import glob\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.distributions import MultivariateNormal\n",
    "from torch.distributions import Categorical\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import gym\n",
    "\n",
    "\n",
    "################################## set device ##################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    \n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "################################## PPO Policy ##################################\n",
    "\n",
    "\n",
    "class RolloutBuffer:\n",
    "    def __init__(self):\n",
    "        self.actions = []\n",
    "        self.states = []\n",
    "        self.logprobs = []\n",
    "        self.rewards = []\n",
    "        self.is_terminals = []\n",
    "    \n",
    "\n",
    "    def clear(self):\n",
    "        del self.actions[:]\n",
    "        del self.states[:]\n",
    "        del self.logprobs[:]\n",
    "        del self.rewards[:]\n",
    "        del self.is_terminals[:]\n",
    "\n",
    "\n",
    "class ActorCritic(nn.Module):\n",
    "    def __init__(self, state_dim, action_dim, has_continuous_action_space, action_std_init):\n",
    "        super(ActorCritic, self).__init__()\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_dim = action_dim\n",
    "            self.action_var = torch.full((action_dim,), action_std_init * action_std_init).to(device)\n",
    "\n",
    "        # actor\n",
    "        if has_continuous_action_space :\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Tanh()\n",
    "                        )\n",
    "        else:\n",
    "            self.actor = nn.Sequential(\n",
    "                            nn.Linear(state_dim, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, 64),\n",
    "                            nn.Tanh(),\n",
    "                            nn.Linear(64, action_dim),\n",
    "                            nn.Softmax(dim=-1)\n",
    "                        )\n",
    "\n",
    "        \n",
    "        # critic\n",
    "        self.critic = nn.Sequential(\n",
    "                        nn.Linear(state_dim, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 64),\n",
    "                        nn.Tanh(),\n",
    "                        nn.Linear(64, 1)\n",
    "                    )\n",
    "        \n",
    "    def set_action_std(self, new_action_std):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_var = torch.full((self.action_dim,), new_action_std * new_action_std).to(device)\n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling ActorCritic::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        raise NotImplementedError\n",
    "    \n",
    "\n",
    "    def act(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            cov_mat = torch.diag(self.action_var).unsqueeze(dim=0)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action = dist.sample()\n",
    "        action_logprob = dist.log_prob(action)\n",
    "        \n",
    "        return action.detach(), action_logprob.detach()\n",
    "    \n",
    "\n",
    "    def evaluate(self, state, action):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            action_mean = self.actor(state)\n",
    "            action_var = self.action_var.expand_as(action_mean)\n",
    "            cov_mat = torch.diag_embed(action_var).to(device)\n",
    "            dist = MultivariateNormal(action_mean, cov_mat)\n",
    "            \n",
    "            # for single action continuous environments\n",
    "            if self.action_dim == 1:\n",
    "                action = action.reshape(-1, self.action_dim)\n",
    "\n",
    "        else:\n",
    "            action_probs = self.actor(state)\n",
    "            dist = Categorical(action_probs)\n",
    "\n",
    "        action_logprobs = dist.log_prob(action)\n",
    "        dist_entropy = dist.entropy()\n",
    "        state_values = self.critic(state)\n",
    "        \n",
    "        return action_logprobs, state_values, dist_entropy\n",
    "\n",
    "\n",
    "class PPO:\n",
    "    def __init__(self, state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std_init=0.6):\n",
    "\n",
    "        self.has_continuous_action_space = has_continuous_action_space\n",
    "\n",
    "        if has_continuous_action_space:\n",
    "            self.action_std = action_std_init\n",
    "\n",
    "        self.gamma = gamma\n",
    "        self.eps_clip = eps_clip\n",
    "        self.K_epochs = K_epochs\n",
    "        \n",
    "        self.buffer = RolloutBuffer()\n",
    "\n",
    "        self.policy = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.optimizer = torch.optim.Adam([\n",
    "                        {'params': self.policy.actor.parameters(), 'lr': lr_actor},\n",
    "                        {'params': self.policy.critic.parameters(), 'lr': lr_critic}\n",
    "                    ])\n",
    "\n",
    "        self.policy_old = ActorCritic(state_dim, action_dim, has_continuous_action_space, action_std_init).to(device)\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "        \n",
    "        self.MseLoss = nn.MSELoss()\n",
    "\n",
    "\n",
    "    def set_action_std(self, new_action_std):\n",
    "        \n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = new_action_std\n",
    "            self.policy.set_action_std(new_action_std)\n",
    "            self.policy_old.set_action_std(new_action_std)\n",
    "        \n",
    "        else:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"WARNING : Calling PPO::set_action_std() on discrete action space policy\")\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def decay_action_std(self, action_std_decay_rate, min_action_std):\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            self.action_std = self.action_std - action_std_decay_rate\n",
    "            self.action_std = round(self.action_std, 4)\n",
    "            if (self.action_std <= min_action_std):\n",
    "                self.action_std = min_action_std\n",
    "                print(\"setting actor output action_std to min_action_std : \", self.action_std)\n",
    "            else:\n",
    "                print(\"setting actor output action_std to : \", self.action_std)\n",
    "            self.set_action_std(self.action_std)\n",
    "\n",
    "        else:\n",
    "            print(\"WARNING : Calling PPO::decay_action_std() on discrete action space policy\")\n",
    "\n",
    "        print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "\n",
    "        if self.has_continuous_action_space:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "\n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.detach().cpu().numpy().flatten()\n",
    "\n",
    "        else:\n",
    "            with torch.no_grad():\n",
    "                state = torch.FloatTensor(state).to(device)\n",
    "                action, action_logprob = self.policy_old.act(state)\n",
    "            \n",
    "            self.buffer.states.append(state)\n",
    "            self.buffer.actions.append(action)\n",
    "            self.buffer.logprobs.append(action_logprob)\n",
    "\n",
    "            return action.item()\n",
    "\n",
    "\n",
    "    def update(self):\n",
    "\n",
    "        # Monte Carlo estimate of returns\n",
    "        rewards = []\n",
    "        discounted_reward = 0\n",
    "        for reward, is_terminal in zip(reversed(self.buffer.rewards), reversed(self.buffer.is_terminals)):\n",
    "            if is_terminal:\n",
    "                discounted_reward = 0\n",
    "            discounted_reward = reward + (self.gamma * discounted_reward)\n",
    "            rewards.insert(0, discounted_reward)\n",
    "            \n",
    "        # Normalizing the rewards\n",
    "        rewards = torch.tensor(rewards, dtype=torch.float32).to(device)\n",
    "        rewards = (rewards - rewards.mean()) / (rewards.std() + 1e-7)\n",
    "\n",
    "        # convert list to tensor\n",
    "        old_states = torch.squeeze(torch.stack(self.buffer.states, dim=0)).detach().to(device)\n",
    "        old_actions = torch.squeeze(torch.stack(self.buffer.actions, dim=0)).detach().to(device)\n",
    "        old_logprobs = torch.squeeze(torch.stack(self.buffer.logprobs, dim=0)).detach().to(device)\n",
    "\n",
    "        \n",
    "        # Optimize policy for K epochs\n",
    "        for _ in range(self.K_epochs):\n",
    "\n",
    "            # Evaluating old actions and values\n",
    "            logprobs, state_values, dist_entropy = self.policy.evaluate(old_states, old_actions)\n",
    "\n",
    "            # match state_values tensor dimensions with rewards tensor\n",
    "            state_values = torch.squeeze(state_values)\n",
    "            \n",
    "            # Finding the ratio (pi_theta / pi_theta__old)\n",
    "            ratios = torch.exp(logprobs - old_logprobs.detach())\n",
    "\n",
    "            # Finding Surrogate Loss\n",
    "            advantages = rewards - state_values.detach()   \n",
    "            surr1 = ratios * advantages\n",
    "            surr2 = torch.clamp(ratios, 1-self.eps_clip, 1+self.eps_clip) * advantages\n",
    "\n",
    "            # final loss of clipped objective PPO\n",
    "            loss = -torch.min(surr1, surr2) + 0.5*self.MseLoss(state_values, rewards) - 0.01*dist_entropy\n",
    "            \n",
    "            # take gradient step\n",
    "            self.optimizer.zero_grad()\n",
    "            loss.mean().backward()\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        # Copy new weights into old policy\n",
    "        self.policy_old.load_state_dict(self.policy.state_dict())\n",
    "\n",
    "        # clear buffer\n",
    "        self.buffer.clear()\n",
    "    \n",
    "    \n",
    "    def save(self, checkpoint_path):\n",
    "        torch.save(self.policy_old.state_dict(), checkpoint_path)\n",
    "   \n",
    "\n",
    "    def load(self, checkpoint_path):\n",
    "        self.policy_old.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))\n",
    "        self.policy.load_state_dict(torch.load(checkpoint_path, map_location=lambda storage, loc: storage))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "training environment name : CartPole-v1\n",
      "current logging run number for CartPole-v1 :  2\n",
      "logging at : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_2.csv\n",
      "save checkpoint path : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "max training timesteps :  100000\n",
      "max timesteps per episode :  400\n",
      "model saving frequency : 20000 timesteps\n",
      "log frequency : 800 timesteps\n",
      "printing average reward over episodes in last : 1600 timesteps\n",
      "--------------------------------------------------------------------------------------------\n",
      "state space dimension :  4\n",
      "action space dimension :  2\n",
      "--------------------------------------------------------------------------------------------\n",
      "Initializing a discrete action space policy\n",
      "--------------------------------------------------------------------------------------------\n",
      "PPO update frequency : 1600 timesteps\n",
      "PPO K epochs :  40\n",
      "PPO epsilon clip :  0.2\n",
      "discount factor (gamma) :  0.99\n",
      "--------------------------------------------------------------------------------------------\n",
      "optimizer learning rate actor :  0.0003\n",
      "optimizer learning rate critic :  0.001\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2022-05-20 19:42:12\n",
      "============================================================================================\n",
      "Episode : 81 \t\t Timestep : 1600 \t\t Average Reward : 19.7\n",
      "Episode : 138 \t\t Timestep : 3200 \t\t Average Reward : 27.67\n",
      "Episode : 183 \t\t Timestep : 4800 \t\t Average Reward : 36.09\n",
      "Episode : 215 \t\t Timestep : 6400 \t\t Average Reward : 47.88\n",
      "Episode : 235 \t\t Timestep : 8000 \t\t Average Reward : 80.2\n",
      "Episode : 251 \t\t Timestep : 9600 \t\t Average Reward : 102.81\n",
      "Episode : 259 \t\t Timestep : 11200 \t\t Average Reward : 196.62\n",
      "Episode : 266 \t\t Timestep : 12800 \t\t Average Reward : 228.86\n",
      "Episode : 275 \t\t Timestep : 14400 \t\t Average Reward : 175.56\n",
      "Episode : 280 \t\t Timestep : 16000 \t\t Average Reward : 309.6\n",
      "Episode : 286 \t\t Timestep : 17600 \t\t Average Reward : 225.17\n",
      "Episode : 290 \t\t Timestep : 19200 \t\t Average Reward : 397.75\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:22\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 295 \t\t Timestep : 20800 \t\t Average Reward : 352.8\n",
      "Episode : 299 \t\t Timestep : 22400 \t\t Average Reward : 367.0\n",
      "Episode : 308 \t\t Timestep : 24000 \t\t Average Reward : 192.11\n",
      "Episode : 315 \t\t Timestep : 25600 \t\t Average Reward : 243.57\n",
      "Episode : 320 \t\t Timestep : 27200 \t\t Average Reward : 326.6\n",
      "Episode : 324 \t\t Timestep : 28800 \t\t Average Reward : 400.0\n",
      "Episode : 328 \t\t Timestep : 30400 \t\t Average Reward : 339.25\n",
      "Episode : 333 \t\t Timestep : 32000 \t\t Average Reward : 364.0\n",
      "Episode : 337 \t\t Timestep : 33600 \t\t Average Reward : 400.0\n",
      "Episode : 343 \t\t Timestep : 35200 \t\t Average Reward : 219.67\n",
      "Episode : 347 \t\t Timestep : 36800 \t\t Average Reward : 400.0\n",
      "Episode : 352 \t\t Timestep : 38400 \t\t Average Reward : 364.2\n",
      "Episode : 356 \t\t Timestep : 40000 \t\t Average Reward : 400.0\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:00:44\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 360 \t\t Timestep : 41600 \t\t Average Reward : 400.0\n",
      "Episode : 364 \t\t Timestep : 43200 \t\t Average Reward : 372.5\n",
      "Episode : 368 \t\t Timestep : 44800 \t\t Average Reward : 381.5\n",
      "Episode : 372 \t\t Timestep : 46400 \t\t Average Reward : 400.0\n",
      "Episode : 377 \t\t Timestep : 48000 \t\t Average Reward : 379.2\n",
      "Episode : 381 \t\t Timestep : 49600 \t\t Average Reward : 375.75\n",
      "Episode : 385 \t\t Timestep : 51200 \t\t Average Reward : 389.75\n",
      "Episode : 390 \t\t Timestep : 52800 \t\t Average Reward : 317.6\n",
      "Episode : 395 \t\t Timestep : 54400 \t\t Average Reward : 345.6\n",
      "Episode : 400 \t\t Timestep : 56000 \t\t Average Reward : 328.2\n",
      "Episode : 404 \t\t Timestep : 57600 \t\t Average Reward : 364.75\n",
      "Episode : 408 \t\t Timestep : 59200 \t\t Average Reward : 400.0\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:04\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 412 \t\t Timestep : 60800 \t\t Average Reward : 362.0\n",
      "Episode : 416 \t\t Timestep : 62400 \t\t Average Reward : 385.0\n",
      "Episode : 421 \t\t Timestep : 64000 \t\t Average Reward : 394.4\n",
      "Episode : 425 \t\t Timestep : 65600 \t\t Average Reward : 400.0\n",
      "Episode : 429 \t\t Timestep : 67200 \t\t Average Reward : 400.0\n",
      "Episode : 433 \t\t Timestep : 68800 \t\t Average Reward : 400.0\n",
      "Episode : 437 \t\t Timestep : 70400 \t\t Average Reward : 400.0\n",
      "Episode : 441 \t\t Timestep : 72000 \t\t Average Reward : 400.0\n",
      "Episode : 445 \t\t Timestep : 73600 \t\t Average Reward : 308.5\n",
      "Episode : 449 \t\t Timestep : 75200 \t\t Average Reward : 400.0\n",
      "Episode : 455 \t\t Timestep : 76800 \t\t Average Reward : 302.5\n",
      "Episode : 459 \t\t Timestep : 78400 \t\t Average Reward : 400.0\n",
      "Episode : 463 \t\t Timestep : 80000 \t\t Average Reward : 400.0\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:26\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode : 467 \t\t Timestep : 81600 \t\t Average Reward : 400.0\n",
      "Episode : 471 \t\t Timestep : 83200 \t\t Average Reward : 400.0\n",
      "Episode : 475 \t\t Timestep : 84800 \t\t Average Reward : 400.0\n",
      "Episode : 480 \t\t Timestep : 86400 \t\t Average Reward : 341.8\n",
      "Episode : 484 \t\t Timestep : 88000 \t\t Average Reward : 400.0\n",
      "Episode : 488 \t\t Timestep : 89600 \t\t Average Reward : 393.25\n",
      "Episode : 492 \t\t Timestep : 91200 \t\t Average Reward : 400.0\n",
      "Episode : 497 \t\t Timestep : 92800 \t\t Average Reward : 288.6\n",
      "Episode : 502 \t\t Timestep : 94400 \t\t Average Reward : 340.0\n",
      "Episode : 506 \t\t Timestep : 96000 \t\t Average Reward : 400.0\n",
      "Episode : 510 \t\t Timestep : 97600 \t\t Average Reward : 353.5\n",
      "Episode : 514 \t\t Timestep : 99200 \t\t Average Reward : 398.25\n",
      "--------------------------------------------------------------------------------------------\n",
      "saving model at : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "model saved\n",
      "Elapsed Time  :  0:01:48\n",
      "--------------------------------------------------------------------------------------------\n",
      "============================================================================================\n",
      "Started training at (GMT) :  2022-05-20 19:42:12\n",
      "Finished training at (GMT) :  2022-05-20 19:44:00\n",
      "Total training time  :  0:01:48\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "################################### Training ###################################\n",
    "\n",
    "\n",
    "####### initialize environment hyperparameters ######\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "has_continuous_action_space = False\n",
    "\n",
    "max_ep_len = 400                    # max timesteps in one episode\n",
    "max_training_timesteps = int(1e5)   # break training loop if timeteps > max_training_timesteps\n",
    "\n",
    "print_freq = max_ep_len * 4     # print avg reward in the interval (in num timesteps)\n",
    "log_freq = max_ep_len * 2       # log avg reward in the interval (in num timesteps)\n",
    "save_model_freq = int(2e4)      # save model frequency (in num timesteps)\n",
    "\n",
    "action_std = None\n",
    "\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "## Note : print/log frequencies should be > than max_ep_len\n",
    "\n",
    "\n",
    "################ PPO hyperparameters ################\n",
    "\n",
    "\n",
    "update_timestep = max_ep_len * 4      # update policy every n timesteps\n",
    "K_epochs = 40               # update policy for K epochs\n",
    "eps_clip = 0.2              # clip parameter for PPO\n",
    "gamma = 0.99                # discount factor\n",
    "\n",
    "lr_actor = 0.0003       # learning rate for actor network\n",
    "lr_critic = 0.001       # learning rate for critic network\n",
    "\n",
    "random_seed = 0         # set random seed if required (0 = no random seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "\n",
    "print(\"training environment name : \" + env_name)\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "# state space dimension\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "# action space dimension\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "\n",
    "\n",
    "###################### logging ######################\n",
    "\n",
    "#### log files for multiple runs are NOT overwritten\n",
    "\n",
    "log_dir = \"PPO_logs\"\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "log_dir = log_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(log_dir):\n",
    "      os.makedirs(log_dir)\n",
    "\n",
    "\n",
    "#### get number of log files in log directory\n",
    "run_num = 0\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "run_num = len(current_num_files)\n",
    "\n",
    "\n",
    "#### create new log file for each run \n",
    "log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "\n",
    "print(\"current logging run number for \" + env_name + \" : \", run_num)\n",
    "print(\"logging at : \" + log_f_name)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "################### checkpointing ###################\n",
    "\n",
    "run_num_pretrained = 0      #### change this to prevent overwriting weights in same env_name folder\n",
    "\n",
    "directory = \"PPO_preTrained\"\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "directory = directory + '/' + env_name + '/'\n",
    "if not os.path.exists(directory):\n",
    "      os.makedirs(directory)\n",
    "\n",
    "\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"save checkpoint path : \" + checkpoint_path)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "\n",
    "############# print all hyperparameters #############\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"max training timesteps : \", max_training_timesteps)\n",
    "print(\"max timesteps per episode : \", max_ep_len)\n",
    "\n",
    "print(\"model saving frequency : \" + str(save_model_freq) + \" timesteps\")\n",
    "print(\"log frequency : \" + str(log_freq) + \" timesteps\")\n",
    "print(\"printing average reward over episodes in last : \" + str(print_freq) + \" timesteps\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"state space dimension : \", state_dim)\n",
    "print(\"action space dimension : \", action_dim)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    print(\"Initializing a continuous action space policy\")\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"starting std of action distribution : \", action_std)\n",
    "    print(\"decay rate of std of action distribution : \", action_std_decay_rate)\n",
    "    print(\"minimum std of action distribution : \", min_action_std)\n",
    "    print(\"decay frequency of std of action distribution : \" + str(action_std_decay_freq) + \" timesteps\")\n",
    "\n",
    "else:\n",
    "    print(\"Initializing a discrete action space policy\")\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"PPO update frequency : \" + str(update_timestep) + \" timesteps\") \n",
    "print(\"PPO K epochs : \", K_epochs)\n",
    "print(\"PPO epsilon clip : \", eps_clip)\n",
    "print(\"discount factor (gamma) : \", gamma)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "print(\"optimizer learning rate actor : \", lr_actor)\n",
    "print(\"optimizer learning rate critic : \", lr_critic)\n",
    "\n",
    "if random_seed:\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "    print(\"setting random seed to \", random_seed)\n",
    "    torch.manual_seed(random_seed)\n",
    "    env.seed(random_seed)\n",
    "    np.random.seed(random_seed)\n",
    "\n",
    "#####################################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "################# training procedure ################\n",
    "\n",
    "# initialize a PPO agent\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "\n",
    "# track total training time\n",
    "start_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# logging file\n",
    "log_f = open(log_f_name,\"w+\")\n",
    "log_f.write('episode,timestep,reward\\n')\n",
    "\n",
    "\n",
    "# printing and logging variables\n",
    "print_running_reward = 0\n",
    "print_running_episodes = 0\n",
    "\n",
    "log_running_reward = 0\n",
    "log_running_episodes = 0\n",
    "\n",
    "time_step = 0\n",
    "i_episode = 0\n",
    "\n",
    "\n",
    "# training loop\n",
    "while time_step <= max_training_timesteps:\n",
    "    \n",
    "    state = env.reset()\n",
    "    current_ep_reward = 0\n",
    "\n",
    "    for t in range(1, max_ep_len+1):\n",
    "        \n",
    "        # select action with policy\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        \n",
    "        # saving reward and is_terminals\n",
    "        ppo_agent.buffer.rewards.append(reward)\n",
    "        ppo_agent.buffer.is_terminals.append(done)\n",
    "        \n",
    "        time_step +=1\n",
    "        current_ep_reward += reward\n",
    "\n",
    "        # update PPO agent\n",
    "        if time_step % update_timestep == 0:\n",
    "            ppo_agent.update()\n",
    "\n",
    "        # if continuous action space; then decay action std of ouput action distribution\n",
    "        if has_continuous_action_space and time_step % action_std_decay_freq == 0:\n",
    "            ppo_agent.decay_action_std(action_std_decay_rate, min_action_std)\n",
    "\n",
    "        # log in logging file\n",
    "        if time_step % log_freq == 0:\n",
    "\n",
    "            # log average reward till last episode\n",
    "            log_avg_reward = log_running_reward / log_running_episodes\n",
    "            log_avg_reward = round(log_avg_reward, 4)\n",
    "\n",
    "            log_f.write('{},{},{}\\n'.format(i_episode, time_step, log_avg_reward))\n",
    "            log_f.flush()\n",
    "\n",
    "            log_running_reward = 0\n",
    "            log_running_episodes = 0\n",
    "\n",
    "        # printing average reward\n",
    "        if time_step % print_freq == 0:\n",
    "\n",
    "            # print average reward till last episode\n",
    "            print_avg_reward = print_running_reward / print_running_episodes\n",
    "            print_avg_reward = round(print_avg_reward, 2)\n",
    "\n",
    "            print(\"Episode : {} \\t\\t Timestep : {} \\t\\t Average Reward : {}\".format(i_episode, time_step, print_avg_reward))\n",
    "\n",
    "            print_running_reward = 0\n",
    "            print_running_episodes = 0\n",
    "            \n",
    "        # save model weights\n",
    "        if time_step % save_model_freq == 0:\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            print(\"saving model at : \" + checkpoint_path)\n",
    "            ppo_agent.save(checkpoint_path)\n",
    "            print(\"model saved\")\n",
    "            print(\"Elapsed Time  : \", datetime.now().replace(microsecond=0) - start_time)\n",
    "            print(\"--------------------------------------------------------------------------------------------\")\n",
    "            \n",
    "        # break; if the episode is over\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    print_running_reward += current_ep_reward\n",
    "    print_running_episodes += 1\n",
    "\n",
    "    log_running_reward += current_ep_reward\n",
    "    log_running_episodes += 1\n",
    "\n",
    "    i_episode += 1\n",
    "\n",
    "\n",
    "log_f.close()\n",
    "env.close()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# print total training time\n",
    "print(\"============================================================================================\")\n",
    "end_time = datetime.now().replace(microsecond=0)\n",
    "print(\"Started training at (GMT) : \", start_time)\n",
    "print(\"Finished training at (GMT) : \", end_time)\n",
    "print(\"Total training time  : \", end_time - start_time)\n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "loading network from : PPO_preTrained/CartPole-v1/PPO_CartPole-v1_0_0.pth\n",
      "--------------------------------------------------------------------------------------------\n",
      "Episode: 1 \t\t Reward: 500.0\n",
      "Episode: 2 \t\t Reward: 383.0\n",
      "Episode: 3 \t\t Reward: 500.0\n",
      "Episode: 4 \t\t Reward: 327.0\n",
      "Episode: 5 \t\t Reward: 500.0\n",
      "Episode: 6 \t\t Reward: 500.0\n",
      "Episode: 7 \t\t Reward: 500.0\n",
      "Episode: 8 \t\t Reward: 500.0\n",
      "Episode: 9 \t\t Reward: 500.0\n",
      "Episode: 10 \t\t Reward: 328.0\n",
      "============================================================================================\n",
      "average test reward : 453.8\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "#################################### Testing ###################################\n",
    "\n",
    "\n",
    "################## hyperparameters ##################\n",
    "\n",
    "env_name = \"CartPole-v1\"\n",
    "has_continuous_action_space = False\n",
    "max_ep_len = 500\n",
    "action_std = None\n",
    "\n",
    "total_test_episodes = 10\n",
    "\n",
    "K_epochs = 80\n",
    "eps_clip = 0.2\n",
    "gamma = 0.99\n",
    "\n",
    "lr_actor = 0.0003\n",
    "lr_critic = 0.001\n",
    "\n",
    "env = gym.make(env_name)\n",
    "\n",
    "state_dim = env.observation_space.shape[0]\n",
    "\n",
    "if has_continuous_action_space:\n",
    "    action_dim = env.action_space.shape[0]\n",
    "else:\n",
    "    action_dim = env.action_space.n\n",
    "\n",
    "ppo_agent = PPO(state_dim, action_dim, lr_actor, lr_critic, gamma, K_epochs, eps_clip, has_continuous_action_space, action_std)\n",
    "\n",
    "random_seed = 0\n",
    "run_num_pretrained = 0\n",
    "\n",
    "\n",
    "directory = \"PPO_preTrained\" + '/' + env_name + '/'\n",
    "checkpoint_path = directory + \"PPO_{}_{}_{}.pth\".format(env_name, random_seed, run_num_pretrained)\n",
    "print(\"loading network from : \" + checkpoint_path)\n",
    "\n",
    "ppo_agent.load(checkpoint_path)\n",
    "\n",
    "print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "\n",
    "test_running_reward = 0\n",
    "\n",
    "for ep in range(1, total_test_episodes+1):\n",
    "    ep_reward = 0\n",
    "    state = env.reset()\n",
    "    \n",
    "    for t in range(1, max_ep_len+1):\n",
    "        action = ppo_agent.select_action(state)\n",
    "        state, reward, done, _ = env.step(action)\n",
    "        ep_reward += reward\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    ppo_agent.buffer.clear()\n",
    "\n",
    "    test_running_reward +=  ep_reward\n",
    "    print('Episode: {} \\t\\t Reward: {}'.format(ep, round(ep_reward, 2)))\n",
    "    ep_reward = 0\n",
    "\n",
    "env.close()\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "avg_test_reward = test_running_reward / total_test_episodes\n",
    "avg_test_reward = round(avg_test_reward, 2)\n",
    "print(\"average test reward : \" + str(avg_test_reward))\n",
    "\n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "loading data from : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_0.csv\n",
      "data shape :  (125, 3)\n",
      "--------------------------------------------------------------------------------------------\n",
      "loading data from : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_1.csv\n",
      "data shape :  (5, 3)\n",
      "--------------------------------------------------------------------------------------------\n",
      "loading data from : PPO_logs/CartPole-v1//PPO_CartPole-v1_log_2.csv\n",
      "data shape :  (125, 3)\n",
      "--------------------------------------------------------------------------------------------\n",
      "============================================================================================\n",
      "figure saved at :  PPO_figs/CartPole-v1//PPO_CartPole-v1_fig_0.png\n",
      "============================================================================================\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "env_name = 'CartPole-v1'\n",
    "\n",
    "fig_num = 0\n",
    "\n",
    "plot_avg = True\n",
    "\n",
    "fig_width = 10\n",
    "fig_height = 6\n",
    "\n",
    "window_len_smooth = 50\n",
    "min_window_len_smooth = 1\n",
    "linewidth_smooth = 1.5\n",
    "alpha_smooth = 1\n",
    "\n",
    "window_len_var = 5\n",
    "min_window_len_var = 1\n",
    "linewidth_var = 2\n",
    "alpha_var = 0.1\n",
    "\n",
    "\n",
    "colors = ['red', 'blue', 'green', 'orange', 'purple', 'olive', 'brown', 'magenta', 'cyan', 'crimson','gray', 'black']\n",
    "\n",
    "\n",
    "# make directory for saving figures\n",
    "figures_dir = \"PPO_figs\"\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "\n",
    "# make environment directory for saving figures\n",
    "figures_dir = figures_dir + '/' + env_name + '/'\n",
    "if not os.path.exists(figures_dir):\n",
    "    os.makedirs(figures_dir)\n",
    "\n",
    "\n",
    "fig_save_path = figures_dir + '/PPO_' + env_name + '_fig_' + str(fig_num) + '.png'\n",
    "\n",
    "\n",
    "# get number of log files in directory\n",
    "log_dir = \"PPO_logs\" + '/' + env_name + '/'\n",
    "\n",
    "current_num_files = next(os.walk(log_dir))[2]\n",
    "num_runs = len(current_num_files)\n",
    "\n",
    "\n",
    "all_runs = []\n",
    "\n",
    "for run_num in range(num_runs):\n",
    "\n",
    "    log_f_name = log_dir + '/PPO_' + env_name + \"_log_\" + str(run_num) + \".csv\"\n",
    "    print(\"loading data from : \" + log_f_name)\n",
    "    data = pd.read_csv(log_f_name)\n",
    "    data = pd.DataFrame(data)\n",
    "    \n",
    "    print(\"data shape : \", data.shape)\n",
    "    \n",
    "    all_runs.append(data)\n",
    "    print(\"--------------------------------------------------------------------------------------------\")\n",
    "\n",
    "\n",
    "ax = plt.gca()\n",
    "\n",
    "if plot_avg:\n",
    "    df_concat = pd.concat(all_runs)\n",
    "    df_concat_groupby = df_concat.groupby(df_concat.index)\n",
    "    data_avg = df_concat_groupby.mean()\n",
    "\n",
    "    data_avg['reward_smooth'] = data_avg['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
    "    data_avg['reward_var'] = data_avg['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
    "\n",
    "    data_avg.plot(kind='line', x='timestep' , y='reward_smooth',ax=ax,color=colors[0],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
    "    data_avg.plot(kind='line', x='timestep' , y='reward_var',ax=ax,color=colors[0],  linewidth=linewidth_var, alpha=alpha_var)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    ax.legend([handles[0]], [\"reward_avg_\" + str(len(all_runs)) + \"_runs\"], loc=2)\n",
    "\n",
    "\n",
    "else:\n",
    "    for i, run in enumerate(all_runs):\n",
    "        run['reward_smooth_' + str(i)] = run['reward'].rolling(window=window_len_smooth, win_type='triang', min_periods=min_window_len_smooth).mean()\n",
    "        run['reward_var_' + str(i)] = run['reward'].rolling(window=window_len_var, win_type='triang', min_periods=min_window_len_var).mean()\n",
    "\n",
    "        run.plot(kind='line', x='timestep' , y='reward_smooth_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_smooth, alpha=alpha_smooth)\n",
    "        run.plot(kind='line', x='timestep' , y='reward_var_' + str(i),ax=ax,color=colors[i % len(colors)],  linewidth=linewidth_var, alpha=alpha_var)\n",
    "\n",
    "    handles, labels = ax.get_legend_handles_labels()\n",
    "    new_handles = []\n",
    "    new_labels = []\n",
    "    for i in range(len(handles)):\n",
    "        if(i%2 == 0):\n",
    "            new_handles.append(handles[i])\n",
    "            new_labels.append(labels[i])\n",
    "    ax.legend(new_handles, new_labels, loc=2)\n",
    "\n",
    "ax.grid(color='gray', linestyle='-', linewidth=1, alpha=0.2)\n",
    "\n",
    "ax.set_xlabel(\"Timesteps\", fontsize=12)\n",
    "ax.set_ylabel(\"Rewards\", fontsize=12)\n",
    "\n",
    "plt.title(env_name, fontsize=14)\n",
    "\n",
    "\n",
    "fig = plt.gcf()\n",
    "fig.set_size_inches(fig_width, fig_height)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "plt.savefig(fig_save_path)\n",
    "print(\"figure saved at : \", fig_save_path)\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================================================\n",
      "Device set to : NVIDIA GeForce RTX 2070 SUPER\n",
      "============================================================================================\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import math\n",
    "import random\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import namedtuple, deque\n",
    "from itertools import count\n",
    "from PIL import Image\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as T\n",
    "\n",
    "\n",
    "env = gym.make('CartPole-v1').unwrapped\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "################################## set device ##################################\n",
    "\n",
    "print(\"============================================================================================\")\n",
    "\n",
    "\n",
    "# set device to cpu or cuda\n",
    "device = torch.device('cpu')\n",
    "\n",
    "if(torch.cuda.is_available()): \n",
    "    device = torch.device('cuda:0') \n",
    "    torch.cuda.empty_cache()\n",
    "    print(\"Device set to : \" + str(torch.cuda.get_device_name(device)))\n",
    "else:\n",
    "    print(\"Device set to : cpu\")\n",
    "    \n",
    "print(\"============================================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([],maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN(nn.Module):\n",
    "\n",
    "    def __init__(self, h, w, outputs):\n",
    "        super(DQN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 16, kernel_size=5, stride=2)\n",
    "        self.bn1 = nn.BatchNorm2d(16)\n",
    "        self.conv2 = nn.Conv2d(16, 32, kernel_size=5, stride=2)\n",
    "        self.bn2 = nn.BatchNorm2d(32)\n",
    "        self.conv3 = nn.Conv2d(32, 32, kernel_size=5, stride=2)\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "\n",
    "        # Number of Linear input connections depends on output of conv2d layers\n",
    "        # and therefore the input image size, so compute it.\n",
    "        def conv2d_size_out(size, kernel_size = 5, stride = 2):\n",
    "            return (size - (kernel_size - 1) - 1) // stride  + 1\n",
    "        convw = conv2d_size_out(conv2d_size_out(conv2d_size_out(w)))\n",
    "        convh = conv2d_size_out(conv2d_size_out(conv2d_size_out(h)))\n",
    "        linear_input_size = convw * convh * 32\n",
    "        self.head = nn.Linear(linear_input_size, outputs)\n",
    "\n",
    "    # Called with either one element to determine next action, or a batch\n",
    "    # during optimization. Returns tensor([[left0exp,right0exp]...]).\n",
    "    def forward(self, x):\n",
    "        x = x.to(device)\n",
    "        x = F.relu(self.bn1(self.conv1(x)))\n",
    "        x = F.relu(self.bn2(self.conv2(x)))\n",
    "        x = F.relu(self.bn3(self.conv3(x)))\n",
    "        return self.head(x.view(x.size(0), -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\JN\\lib\\site-packages\\torchvision\\transforms\\transforms.py:280: UserWarning: Argument interpolation should be of type InterpolationMode instead of int. Please, use InterpolationMode enum.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "resize = T.Compose([T.ToPILImage(),\n",
    "                    T.Resize(40, interpolation=Image.CUBIC),\n",
    "                    T.ToTensor()])\n",
    "\n",
    "\n",
    "def get_cart_location(screen_width):\n",
    "    world_width = env.x_threshold * 2\n",
    "    scale = screen_width / world_width\n",
    "    return int(env.state[0] * scale + screen_width / 2.0)  # MIDDLE OF CART\n",
    "\n",
    "def get_screen():\n",
    "    # Returned screen requested by gym is 400x600x3, but is sometimes larger\n",
    "    # such as 800x1200x3. Transpose it into torch order (CHW).\n",
    "    screen = env.render(mode='rgb_array').transpose((2, 0, 1))\n",
    "    # Cart is in the lower half, so strip off the top and bottom of the screen\n",
    "    _, screen_height, screen_width = screen.shape\n",
    "    screen = screen[:, int(screen_height*0.4):int(screen_height * 0.8)]\n",
    "    view_width = int(screen_width * 0.6)\n",
    "    cart_location = get_cart_location(screen_width)\n",
    "    if cart_location < view_width // 2:\n",
    "        slice_range = slice(view_width)\n",
    "    elif cart_location > (screen_width - view_width // 2):\n",
    "        slice_range = slice(-view_width, None)\n",
    "    else:\n",
    "        slice_range = slice(cart_location - view_width // 2,\n",
    "                            cart_location + view_width // 2)\n",
    "    # Strip off the edges, so that we have a square image centered on a cart\n",
    "    screen = screen[:, :, slice_range]\n",
    "    # Convert to float, rescale, convert to torch tensor\n",
    "    # (this doesn't require a copy)\n",
    "    screen = np.ascontiguousarray(screen, dtype=np.float32) / 255\n",
    "    screen = torch.from_numpy(screen)\n",
    "    # Resize, and add a batch dimension (BCHW)\n",
    "    return resize(screen).unsqueeze(0)\n",
    "\n",
    "\n",
    "env.reset()\n",
    "plt.figure()\n",
    "plt.imshow(get_screen().cpu().squeeze(0).permute(1, 2, 0).numpy(),\n",
    "           interpolation='none')\n",
    "plt.title('Example extracted screen')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.999\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "TARGET_UPDATE = 10\n",
    "\n",
    "# Get screen size so that we can initialize layers correctly based on shape\n",
    "# returned from AI gym. Typical dimensions at this point are close to 3x40x90\n",
    "# which is the result of a clamped and down-scaled render buffer in get_screen()\n",
    "init_screen = get_screen()\n",
    "_, _, screen_height, screen_width = init_screen.shape\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_actions = env.action_space.n\n",
    "\n",
    "policy_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net = DQN(screen_height, screen_width, n_actions).to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "target_net.eval()\n",
    "\n",
    "optimizer = optim.RMSprop(policy_net.parameters())\n",
    "memory = ReplayMemory(10000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(state):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(state).max(1)[1].view(1, 1)\n",
    "    else:\n",
    "        return torch.tensor([[random.randrange(n_actions)]], device=device, dtype=torch.long)\n",
    "\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2)\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "\n",
    "    plt.pause(0.001)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch. This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.cat(batch.state)\n",
    "    action_batch = torch.cat(batch.action)\n",
    "    reward_batch = torch.cat(batch.reward)\n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    next_state_values[non_final_mask] = target_net(non_final_next_states).max(1)[0].detach()\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    for param in policy_net.parameters():\n",
    "        param.grad.data.clamp_(-1, 1)\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [11:18<00:00,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import tqdm\n",
    "ep_rew = []\n",
    "num_episodes = 500\n",
    "for i_episode in tqdm.tqdm(range(num_episodes)):\n",
    "    # Initialize the environment and state\n",
    "    env.reset()\n",
    "    last_screen = get_screen()\n",
    "    current_screen = get_screen()\n",
    "    state = current_screen - last_screen\n",
    "    r = 0\n",
    "    for t in count():\n",
    "        # Select and perform an action\n",
    "        action = select_action(state)\n",
    "        _, reward, done, _ = env.step(action.item())\n",
    "        r += reward\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        # Observe new state\n",
    "        last_screen = current_screen\n",
    "        current_screen = get_screen()\n",
    "        if not done:\n",
    "            next_state = current_screen - last_screen\n",
    "        else:\n",
    "            next_state = None\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "        if done:\n",
    "            episode_durations.append(t + 1)\n",
    "            break\n",
    "    ep_rew.append(r)\n",
    "    # Update the target network, copying all weights and biases in DQN\n",
    "    if i_episode % TARGET_UPDATE == 0:\n",
    "        target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "print('Complete')\n",
    "env.render()\n",
    "env.close()\n",
    "plt.ioff()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1454\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(len(episode_durations))\n",
    "plt.figure(2)\n",
    "plt.clf()\n",
    "durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "plt.title('ep_reward')\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Reward')\n",
    "plt.plot(durations_t.numpy())\n",
    "# Take 100 episode averages and plot them too\n",
    "if len(durations_t) >= 100:\n",
    "    means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "    means = torch.cat((torch.zeros(99), means))\n",
    "    plt.plot(means.numpy())"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "f6a9f81596fa0179001e10b6a4153a67c8909fc44e0482d68db56a45faca03cb"
  },
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
